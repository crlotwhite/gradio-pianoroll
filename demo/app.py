#!/usr/bin/env python3
"""
Gradio PianoRoll Comprehensive Demo
Description: í”¼ì•„ë…¸ë¡¤ ë…¸íŠ¸ í¸ì§‘, ì˜¤ë””ì˜¤ í•©ì„±, íŠ¹ì„± ë¶„ì„ì„ ëª¨ë‘ ì§€ì›í•˜ëŠ” í†µí•© ë°ëª¨
Author: gradio-pianoroll
"""

import gradio as gr
import numpy as np
import io
import base64
import wave
import tempfile
import os
from gradio_pianoroll import PianoRoll

# librosa ì¶”ê°€ ì„í¬íŠ¸
try:
    import librosa
    LIBROSA_AVAILABLE = True
    print("âœ… librosa ì‚¬ìš© ê°€ëŠ¥")
except ImportError:
    LIBROSA_AVAILABLE = False
    print("âš ï¸ librosaê°€ ì„¤ì¹˜ë˜ì§€ ì•ŠìŒ. ì˜¤ë””ì˜¤ íŠ¹ì„± ë¶„ì„ ê¸°ëŠ¥ì´ ì œí•œë©ë‹ˆë‹¤.")

# í•©ì„±ê¸° ì„¤ì •
SAMPLE_RATE = 44100
MAX_DURATION = 10.0  # ìµœëŒ€ 10ì´ˆ

# ë¡œê·¸ ìµœì í™”ë¥¼ ìœ„í•œ ì „ì—­ ë³€ìˆ˜ë“¤
_last_synthesis_config = {}
_last_wave_type = None
_synthesis_count = 0

def midi_to_frequency(midi_note):
    """MIDI ë…¸íŠ¸ ë²ˆí˜¸ë¥¼ ì£¼íŒŒìˆ˜ë¡œ ë³€í™˜ (A4 = 440Hz)"""
    return 440.0 * (2.0 ** ((midi_note - 69) / 12.0))

def create_adsr_envelope(attack, decay, sustain, release, duration, sample_rate):
    """ADSR ì—”ë²¨ë¡œí”„ ìƒì„±"""
    total_samples = int(duration * sample_rate)
    attack_samples = int(attack * sample_rate)
    decay_samples = int(decay * sample_rate)
    release_samples = int(release * sample_rate)
    sustain_samples = total_samples - attack_samples - decay_samples - release_samples

    # ì„œìŠ¤í…Œì¸ êµ¬ê°„ì´ ìŒìˆ˜ê°€ ë˜ì§€ ì•Šë„ë¡ ì¡°ì •
    if sustain_samples < 0:
        sustain_samples = 0
        total_samples = attack_samples + decay_samples + release_samples

    envelope = np.zeros(total_samples)

    # Attack ë‹¨ê³„
    if attack_samples > 0:
        envelope[:attack_samples] = np.linspace(0, 1, attack_samples)

    # Decay ë‹¨ê³„
    if decay_samples > 0:
        start_idx = attack_samples
        end_idx = attack_samples + decay_samples
        envelope[start_idx:end_idx] = np.linspace(1, sustain, decay_samples)

    # Sustain ë‹¨ê³„
    if sustain_samples > 0:
        start_idx = attack_samples + decay_samples
        end_idx = start_idx + sustain_samples
        envelope[start_idx:end_idx] = sustain

    # Release ë‹¨ê³„
    if release_samples > 0:
        start_idx = attack_samples + decay_samples + sustain_samples
        envelope[start_idx:] = np.linspace(sustain, 0, release_samples)

    return envelope

def generate_sine_wave(frequency, duration, sample_rate):
    """ì‚¬ì¸íŒŒ ìƒì„± - ìˆœìˆ˜í•œ í†¤"""
    t = np.linspace(0, duration, int(duration * sample_rate), False)
    return np.sin(2 * np.pi * frequency * t)

def generate_sawtooth_wave(frequency, duration, sample_rate):
    """í†±ë‹ˆíŒŒ ìƒì„± (ë°°ìŒ í•©ì„± ë°©ì‹) - ë°ê³  ë‚ ì¹´ë¡œìš´ ì†Œë¦¬"""
    t = np.linspace(0, duration, int(duration * sample_rate), False)
    wave = np.zeros_like(t)
    
    # ë°°ìŒ í•©ì„±ìœ¼ë¡œ ë” ìŒì•…ì ì¸ í†±ë‹ˆíŒŒ ìƒì„±
    max_harmonic = min(20, int(sample_rate / (2 * frequency)))  # ë‚˜ì´í€´ìŠ¤íŠ¸ í•œê³„
    for n in range(1, max_harmonic + 1):
        amplitude = 1.0 / n
        wave += amplitude * np.sin(2 * np.pi * frequency * n * t)
    
    return wave / np.max(np.abs(wave)) if np.max(np.abs(wave)) > 0 else wave

def generate_square_wave(frequency, duration, sample_rate):
    """ì‚¬ê°íŒŒ ìƒì„± (ë°°ìŒ í•©ì„± ë°©ì‹) - ê±°ì¹ ê³  ê³µê²©ì ì¸ ì†Œë¦¬"""
    t = np.linspace(0, duration, int(duration * sample_rate), False)
    wave = np.zeros_like(t)
    
    # í™€ìˆ˜ ë°°ìŒë§Œ ì‚¬ìš©í•˜ì—¬ ì‚¬ê°íŒŒ ìƒì„±
    max_harmonic = min(15, int(sample_rate / (2 * frequency)))
    for n in range(1, max_harmonic + 1, 2):  # í™€ìˆ˜ë§Œ
        amplitude = 1.0 / n
        wave += amplitude * np.sin(2 * np.pi * frequency * n * t)
    
    return wave / np.max(np.abs(wave)) if np.max(np.abs(wave)) > 0 else wave

def generate_triangle_wave(frequency, duration, sample_rate):
    """ì‚¼ê°íŒŒ ìƒì„± (ë°°ìŒ í•©ì„± ë°©ì‹) - ë¶€ë“œëŸ½ê³  ë”°ëœ»í•œ ì†Œë¦¬"""
    t = np.linspace(0, duration, int(duration * sample_rate), False)
    wave = np.zeros_like(t)
    
    # í™€ìˆ˜ ë°°ìŒ, n^2ë¡œ ê°ì‡„
    max_harmonic = min(12, int(sample_rate / (2 * frequency)))
    for n in range(1, max_harmonic + 1, 2):  # í™€ìˆ˜ë§Œ
        amplitude = 1.0 / (n * n)
        phase = np.pi if (n-1)//2 % 2 == 1 else 0  # êµëŒ€ë¡œ ìœ„ìƒ ë°˜ì „
        wave += amplitude * np.sin(2 * np.pi * frequency * n * t + phase)
    
    return wave / np.max(np.abs(wave)) if np.max(np.abs(wave)) > 0 else wave

def generate_harmonic_wave(frequency, duration, sample_rate, harmonics=5):
    """í•˜ëª¨ë‹‰ìŠ¤ê°€ ìˆëŠ” ë³µí•© íŒŒí˜• ìƒì„± - í’ë¶€í•œ ë°°ìŒ"""
    t = np.linspace(0, duration, int(duration * sample_rate), False)
    wave = np.zeros_like(t)

    # ê¸°ë³¸ ì£¼íŒŒìˆ˜ (ê°•í•¨)
    wave += 1.0 * np.sin(2 * np.pi * frequency * t)

    # í•˜ëª¨ë‹‰ìŠ¤ ì¶”ê°€ (1/nìœ¼ë¡œ ê°ì†Œí•˜ë˜ ì¢€ ë” ê°•í•˜ê²Œ)
    max_harmonic = min(harmonics, int(sample_rate / (2 * frequency)))
    for n in range(2, max_harmonic + 1):
        amplitude = 0.8 / n  # ë” ê°•í•œ ë°°ìŒ
        wave += amplitude * np.sin(2 * np.pi * frequency * n * t)

    # ì •ê·œí™”
    return wave / np.max(np.abs(wave)) if np.max(np.abs(wave)) > 0 else wave

def generate_fm_wave(frequency, duration, sample_rate, mod_freq=None, mod_depth=3.0):
    """FM íŒŒí˜• ìƒì„± - ê¸ˆì†ì„±, ë²¨ ê°™ì€ ì†Œë¦¬"""
    t = np.linspace(0, duration, int(duration * sample_rate), False)
    
    # ëª¨ë“ˆë ˆì´í„° ì£¼íŒŒìˆ˜ë¥¼ ê¸°ë³¸ ì£¼íŒŒìˆ˜ì— ë¹„ë¡€í•˜ê²Œ ì„¤ì •
    if mod_freq is None:
        mod_freq = frequency * 1.5  # 1.5ë°° ë¹„ìœ¨ë¡œ ë” íŠ¹ì§•ì ì¸ FM ì‚¬ìš´ë“œ
    
    # ëª¨ë“ˆë ˆì´í„°
    modulator = mod_depth * np.sin(2 * np.pi * mod_freq * t)

    # ì£¼íŒŒìˆ˜ ë³€ì¡°ëœ ìºë¦¬ì–´
    carrier = np.sin(2 * np.pi * frequency * t + modulator)

    return carrier

def generate_complex_wave(frequency, duration, sample_rate, wave_type='complex'):
    """ë³µí•© íŒŒí˜• ìƒì„± (ì—¬ëŸ¬ ê¸°ë²• ê²°í•©)"""
    global _last_wave_type
    
    # íŒŒí˜• íƒ€ì…ì´ ë³€ê²½ë˜ì—ˆì„ ë•Œë§Œ ë¡œê·¸ ì¶œë ¥
    if wave_type != _last_wave_type:
        print(f"  ğŸµ íŒŒí˜• ë³€ê²½: {_last_wave_type} â†’ {wave_type}")
        _last_wave_type = wave_type
    
    if wave_type == 'sine':
        return generate_sine_wave(frequency, duration, sample_rate)
    elif wave_type == 'sawtooth':
        return generate_sawtooth_wave(frequency, duration, sample_rate)
    elif wave_type == 'square':
        return generate_square_wave(frequency, duration, sample_rate)
    elif wave_type == 'triangle':
        return generate_triangle_wave(frequency, duration, sample_rate)
    elif wave_type == 'harmonic':
        return generate_harmonic_wave(frequency, duration, sample_rate, harmonics=8)
    elif wave_type == 'fm':
        return generate_fm_wave(frequency, duration, sample_rate, mod_freq=frequency * 2.1, mod_depth=4.0)
    else:  # 'complex' - ë‹¨ìˆœí™”ëœ ë³µí•© íŒŒí˜•
        # í†±ë‹ˆíŒŒ ê¸°ë°˜ì— ì•½ê°„ì˜ FM ì¶”ê°€
        base = generate_sawtooth_wave(frequency, duration, sample_rate) * 0.8
        fm_component = generate_fm_wave(frequency, duration, sample_rate, mod_freq=frequency * 0.7, mod_depth=1.5) * 0.2
        return base + fm_component

def synthesize_audio(piano_roll_data, attack=0.01, decay=0.1, sustain=0.7, release=0.3, wave_type='complex'):
    """PianoRoll ë°ì´í„°ì—ì„œ ì˜¤ë””ì˜¤ í•©ì„± (ADSR + ë‹¤ì–‘í•œ íŒŒí˜•)"""
    global _last_synthesis_config, _synthesis_count
    
    if not piano_roll_data or 'notes' not in piano_roll_data or not piano_roll_data['notes']:
        return None

    notes = piano_roll_data['notes']
    tempo = piano_roll_data.get('tempo', 120)
    pixels_per_beat = piano_roll_data.get('pixelsPerBeat', 80)

    # í˜„ì¬ ì„¤ì •
    current_config = {
        'wave_type': wave_type,
        'attack': round(attack, 3),
        'decay': round(decay, 3), 
        'sustain': round(sustain, 2),
        'release': round(release, 3),
        'tempo': tempo,
        'note_count': len(notes)
    }
    
    # ì„¤ì •ì´ ë³€ê²½ë˜ì—ˆê±°ë‚˜ ì²« ë²ˆì§¸ í•©ì„±ì¼ ë•Œë§Œ ìƒì„¸ ë¡œê·¸ ì¶œë ¥
    config_changed = current_config != _last_synthesis_config
    _synthesis_count += 1
    
    if config_changed or _synthesis_count == 1:
        print(f"ğŸ›ï¸ í•©ì„± ì„¤ì • #{_synthesis_count}: {wave_type} íŒŒí˜•, ADSR({attack:.3f},{decay:.3f},{sustain:.2f},{release:.3f})")
        print(f"ğŸ“ ë…¸íŠ¸ ìˆ˜: {len(notes)}, í…œí¬: {tempo}BPM")
        _last_synthesis_config = current_config.copy()
    else:
        print(f"ğŸ”„ í•©ì„± #{_synthesis_count}: ë™ì¼ ì„¤ì •ìœ¼ë¡œ ì¬í•©ì„±")

    # ì „ì²´ ê¸¸ì´ ê³„ì‚°
    max_end_time = 0
    for note in notes:
        start_seconds = (note['start'] / pixels_per_beat) * (60.0 / tempo)
        duration_seconds = (note['duration'] / pixels_per_beat) * (60.0 / tempo)
        end_time = start_seconds + duration_seconds
        max_end_time = max(max_end_time, end_time)

    total_duration = min(max_end_time + 1.0, MAX_DURATION)
    total_samples = int(total_duration * SAMPLE_RATE)
    audio_buffer = np.zeros(total_samples)

    # íŒŒí˜•ë³„ íš¨ê³¼ ì„¤ì •
    vibrato_settings = {
        'sine': (0.0, 0.0),      # ìˆœìˆ˜í•œ ì‚¬ì¸íŒŒëŠ” íš¨ê³¼ ì—†ìŒ
        'sawtooth': (4.5, 0.015), # ê°€ë²¼ìš´ ë¹„ë¸Œë¼í† 
        'square': (0.0, 0.0),     # ì‚¬ê°íŒŒëŠ” íš¨ê³¼ ì—†ì´ ê±°ì¹ ê²Œ
        'triangle': (5.0, 0.02),  # ë¶€ë“œëŸ¬ìš´ ë¹„ë¸Œë¼í† 
        'harmonic': (4.0, 0.025), # í’ë¶€í•œ ë¹„ë¸Œë¼í† 
        'fm': (6.0, 0.03),        # FMì€ ë” ë¹ ë¥¸ ë¹„ë¸Œë¼í† 
        'complex': (4.5, 0.02)    # ì ë‹¹í•œ ë¹„ë¸Œë¼í† 
    }
    
    tremolo_settings = {
        'sine': (0.0, 0.0),       # ìˆœìˆ˜í•œ ì‚¬ì¸íŒŒëŠ” íš¨ê³¼ ì—†ìŒ  
        'sawtooth': (2.5, 0.08),  # ê°€ë²¼ìš´ íŠ¸ë ˆëª°ë¡œ
        'square': (0.0, 0.0),     # ì‚¬ê°íŒŒëŠ” íš¨ê³¼ ì—†ì´
        'triangle': (3.0, 0.06),  # ë¶€ë“œëŸ¬ìš´ íŠ¸ë ˆëª°ë¡œ
        'harmonic': (2.8, 0.1),   # í’ë¶€í•œ íŠ¸ë ˆëª°ë¡œ
        'fm': (3.5, 0.12),        # FMì€ ë” ê°•í•œ íŠ¸ë ˆëª°ë¡œ
        'complex': (3.0, 0.08)    # ì ë‹¹í•œ íŠ¸ë ˆëª°ë¡œ
    }

    vibrato_freq, vibrato_depth = vibrato_settings.get(wave_type, (4.5, 0.02))
    tremolo_freq, tremolo_depth = tremolo_settings.get(wave_type, (3.0, 0.08))

    # ê° ë…¸íŠ¸ ì²˜ë¦¬ (ê³ ê¸‰ í•©ì„±) - ê°œë³„ ë…¸íŠ¸ ë¡œê·¸ëŠ” ì„¤ì • ë³€ê²½ì‹œì—ë§Œ ì¶œë ¥
    processed_notes = 0
    for i, note in enumerate(notes):
        try:
            pitch = note['pitch']
            velocity = note.get('velocity', 100)
            
            start_seconds = (note['start'] / pixels_per_beat) * (60.0 / tempo)
            duration_seconds = (note['duration'] / pixels_per_beat) * (60.0 / tempo)
            
            if start_seconds >= total_duration:
                continue
                
            if start_seconds + duration_seconds > total_duration:
                duration_seconds = total_duration - start_seconds
                
            if duration_seconds <= 0:
                continue

            frequency = midi_to_frequency(pitch)
            volume = velocity / 127.0

            # ê°œë³„ ë…¸íŠ¸ ë¡œê·¸ëŠ” ì„¤ì •ì´ ë³€ê²½ë˜ì—ˆì„ ë•Œë§Œ ì¶œë ¥ (ìµœëŒ€ 3ê°œ)
            if config_changed and i < 3:
                print(f"  ë…¸íŠ¸ {i+1}: MIDI {pitch} ({frequency:.1f}Hz), {duration_seconds:.2f}ì´ˆ")
            elif config_changed and i == 3:
                print(f"  ... ë° {len(notes)-3}ê°œ ë…¸íŠ¸ ë”")

            # ë³µí•© íŒŒí˜• ìƒì„±
            base_wave = generate_complex_wave(frequency, duration_seconds, SAMPLE_RATE, wave_type)

            # íŒŒí˜•ë³„ íš¨ê³¼ ì ìš©
            t = np.linspace(0, duration_seconds, len(base_wave), False)
            
            # ë¹„ë¸Œë¼í†  (ì£¼íŒŒìˆ˜ ë³€ì¡°) - íŒŒí˜•ë³„ë¡œ ë‹¤ë¥´ê²Œ
            if vibrato_depth > 0:
                vibrato = 1 + vibrato_depth * np.sin(2 * np.pi * vibrato_freq * t)
                vibrato_wave = base_wave * vibrato
            else:
                vibrato_wave = base_wave

            # íŠ¸ë ˆëª°ë¡œ (ì§„í­ ë³€ì¡°) - íŒŒí˜•ë³„ë¡œ ë‹¤ë¥´ê²Œ
            if tremolo_depth > 0:
                tremolo = 1 + tremolo_depth * np.sin(2 * np.pi * tremolo_freq * t)
                final_wave = vibrato_wave * tremolo
            else:
                final_wave = vibrato_wave

            # ADSR ì—”ë²¨ë¡œí”„ ì ìš©
            envelope = create_adsr_envelope(attack, decay, sustain, release, duration_seconds, SAMPLE_RATE)
            final_wave = final_wave[:len(envelope)] * envelope * volume

            # ì˜¤ë””ì˜¤ ë²„í¼ì— ì¶”ê°€
            start_sample = int(start_seconds * SAMPLE_RATE)
            end_sample = start_sample + len(final_wave)
            
            if start_sample < total_samples:
                end_sample = min(end_sample, total_samples)
                audio_length = end_sample - start_sample
                if audio_length > 0:
                    audio_buffer[start_sample:end_sample] += final_wave[:audio_length]
                    processed_notes += 1

        except Exception as e:
            if config_changed:  # ì˜¤ë¥˜ ë¡œê·¸ë„ ì„¤ì • ë³€ê²½ì‹œì—ë§Œ ì¶œë ¥
                print(f"âŒ ë…¸íŠ¸ {note.get('pitch', 'unknown')} í•©ì„± ì˜¤ë¥˜: {e}")
            continue

    # ì •ê·œí™”
    max_amplitude = np.max(np.abs(audio_buffer))
    if max_amplitude > 0:
        audio_buffer = audio_buffer / max_amplitude * 0.9
        print(f"âœ… ì˜¤ë””ì˜¤ í•©ì„± ì™„ë£Œ: {processed_notes}ê°œ ë…¸íŠ¸, {len(audio_buffer)/SAMPLE_RATE:.2f}ì´ˆ")
    else:
        print("âš ï¸ ì˜¤ë””ì˜¤ í•©ì„± ê²°ê³¼ê°€ ë¬´ìŒì…ë‹ˆë‹¤")

    return audio_buffer

def audio_array_to_base64_wav(audio_data, sample_rate):
    """numpy ë°°ì—´ì„ base64 WAVë¡œ ë³€í™˜"""
    if audio_data is None or len(audio_data) == 0:
        return None

    try:
        audio_16bit = (audio_data * 32767).astype(np.int16)
        buffer = io.BytesIO()

        with wave.open(buffer, 'wb') as wav_file:
            wav_file.setnchannels(1)
            wav_file.setsampwidth(2)
            wav_file.setframerate(sample_rate)
            wav_file.writeframes(audio_16bit.tobytes())

        buffer.seek(0)
        wav_data = buffer.read()
        base64_data = base64.b64encode(wav_data).decode('utf-8')
        return f"data:audio/wav;base64,{base64_data}"

    except Exception as e:
        print(f"Base64 WAV ë³€í™˜ ì˜¤ë¥˜: {e}")
        return None

def create_temp_wav_file(audio_data, sample_rate):
    """ì„ì‹œ WAV íŒŒì¼ ìƒì„±"""
    if audio_data is None or len(audio_data) == 0:
        return None

    try:
        audio_16bit = (audio_data * 32767).astype(np.int16)
        temp_fd, temp_path = tempfile.mkstemp(suffix='.wav')

        with wave.open(temp_path, 'wb') as wav_file:
            wav_file.setnchannels(1)
            wav_file.setsampwidth(2)
            wav_file.setframerate(sample_rate)
            wav_file.writeframes(audio_16bit.tobytes())

        os.close(temp_fd)
        return temp_path
    except Exception as e:
        print(f"ì„ì‹œ WAV íŒŒì¼ ìƒì„± ì˜¤ë¥˜: {e}")
        return None

def extract_audio_features(audio_file_path, f0_method="pyin", include_f0=True, include_loudness=True, include_voicing=True):
    """ì˜¤ë””ì˜¤ íŒŒì¼ì—ì„œ F0, loudness, voice/unvoice ì¶”ì¶œ"""
    if not LIBROSA_AVAILABLE:
        return None, "librosaê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•„ ì˜¤ë””ì˜¤ íŠ¹ì„± ë¶„ì„ì„ ìˆ˜í–‰í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤"

    features = {}
    status_messages = []

    try:
        # ì˜¤ë””ì˜¤ ë¡œë“œ (ë¡œê·¸ ìµœì†Œí™”)
        y, sr = librosa.load(audio_file_path, sr=None)
        duration = len(y) / sr
        
        hop_length = 512

        # F0 ì¶”ì¶œ
        if include_f0:
            try:
                if f0_method == "pyin":
                    f0, voiced_flag, voiced_probs = librosa.pyin(
                        y, sr=sr,
                        fmin=librosa.note_to_hz('C2'),
                        fmax=librosa.note_to_hz('C7')
                    )
                else:
                    pitches, magnitudes = librosa.piptrack(y=y, sr=sr)
                    f0 = []
                    for t in range(pitches.shape[1]):
                        index = magnitudes[:, t].argmax()
                        pitch = pitches[index, t]
                        f0.append(pitch if pitch > 0 else np.nan)
                    f0 = np.array(f0)
                    voiced_flag = ~np.isnan(f0)
                    voiced_probs = voiced_flag.astype(float)

                frame_times = librosa.frames_to_time(np.arange(len(f0)), sr=sr, hop_length=hop_length)

                features['f0'] = {
                    'times': frame_times,
                    'f0_values': f0,
                    'voiced_flag': voiced_flag,
                    'voiced_probs': voiced_probs,
                    'sample_rate': sr,
                    'duration': duration,
                    'hop_length': hop_length
                }
                status_messages.append("F0 ì¶”ì¶œ ì™„ë£Œ")
                
                valid_f0 = f0[~np.isnan(f0)]
                if len(valid_f0) > 0:
                    f0_range = f"{np.min(valid_f0):.1f}~{np.max(valid_f0):.1f}Hz"
                    status_messages.append(f"F0ë²”ìœ„: {f0_range}")
                
            except Exception as e:
                status_messages.append(f"F0 ì¶”ì¶œ ì‹¤íŒ¨: {str(e)}")

        # Loudness ì¶”ì¶œ
        if include_loudness:
            try:
                rms_energy = librosa.feature.rms(y=y, hop_length=hop_length)[0]
                frame_times = librosa.frames_to_time(np.arange(len(rms_energy)), sr=sr, hop_length=hop_length)

                # dBë¡œ ë³€í™˜
                max_rms = np.max(rms_energy)
                if max_rms > 0:
                    loudness_db = 20 * np.log10(rms_energy / max_rms)
                    loudness_db = np.maximum(loudness_db, -60)
                else:
                    loudness_db = np.full_like(rms_energy, -60)

                # 0-1ë¡œ ì •ê·œí™”
                loudness_normalized = (loudness_db + 60) / 60

                features['loudness'] = {
                    'times': frame_times,
                    'rms_values': rms_energy,
                    'loudness_db': loudness_db,
                    'loudness_normalized': loudness_normalized,
                    'sample_rate': sr,
                    'duration': duration,
                    'hop_length': hop_length
                }
                status_messages.append("Loudness ì¶”ì¶œ ì™„ë£Œ")
                
                db_range = f"{np.min(loudness_db):.1f}~{np.max(loudness_db):.1f}dB"
                status_messages.append(f"Loudnessë²”ìœ„: {db_range}")
                
            except Exception as e:
                status_messages.append(f"Loudness ì¶”ì¶œ ì‹¤íŒ¨: {str(e)}")

        # Voice/Unvoice ì¶”ì¶œ
        if include_voicing and 'f0' in features:
            try:
                voicing_data = features['f0']  # F0ì—ì„œ voiced ì •ë³´ ì‚¬ìš©
                voiced_ratio = np.sum(voicing_data['voiced_flag']) / len(voicing_data['voiced_flag'])
                
                features['voicing'] = {
                    'times': voicing_data['times'],
                    'voiced_flag': voicing_data['voiced_flag'],
                    'voiced_probs': voicing_data['voiced_probs'],
                    'sample_rate': sr,
                    'duration': duration,
                    'hop_length': hop_length,
                    'voiced_ratio': voiced_ratio
                }
                status_messages.append(f"Voicing ì¶”ì¶œ ì™„ë£Œ ({voiced_ratio:.1%} voiced)")
                
            except Exception as e:
                status_messages.append(f"Voice/Unvoice ì¶”ì¶œ ì‹¤íŒ¨: {str(e)}")

        if features:
            features['duration'] = duration
            features['sample_rate'] = sr
            final_status = f"ë¶„ì„ì™„ë£Œ {duration:.2f}ì´ˆ | " + " | ".join(status_messages)
            return features, final_status
        else:
            return None, "ëª¨ë“  íŠ¹ì„± ì¶”ì¶œ ì‹¤íŒ¨"

    except Exception as e:
        return None, f"ì˜¤ë””ì˜¤ íŠ¹ì„± ë¶„ì„ ì˜¤ë¥˜: {str(e)}"

def create_multi_feature_line_data(features, tempo=120, pixels_per_beat=80):
    """ì—¬ëŸ¬ ì˜¤ë””ì˜¤ íŠ¹ì„±ì„ ê²°í•©í•˜ì—¬ line_data ìƒì„±"""
    combined_line_data = {}

    try:
        # F0 ê³¡ì„  ì¶”ê°€
        if 'f0' in features:
            f0_data = features['f0']
            times = f0_data['times']
            f0_values = f0_data['f0_values']

            # í”¼ì•„ë…¸ë¡¤ ìƒìˆ˜
            NOTE_HEIGHT = 20
            TOTAL_NOTES = 128

            def hz_to_midi(frequency):
                if frequency <= 0:
                    return 0
                return 69 + 12 * np.log2(frequency / 440.0)

            def midi_to_y_coordinate(midi_note):
                return (TOTAL_NOTES - 1 - midi_note) * NOTE_HEIGHT + NOTE_HEIGHT/2

            # F0 ë°ì´í„° í¬ì¸íŠ¸ ìƒì„±
            f0_points = []
            valid_f0_values = []

            for time, f0 in zip(times, f0_values):
                if not np.isnan(f0) and f0 > 0:
                    midi_note = hz_to_midi(f0)
                    if 0 <= midi_note <= 127:
                        x_pixel = time * (tempo / 60) * pixels_per_beat
                        y_pixel = midi_to_y_coordinate(midi_note)
                        f0_points.append({"x": float(x_pixel), "y": float(y_pixel)})
                        valid_f0_values.append(f0)

            if f0_points:
                min_f0 = float(np.min(valid_f0_values))
                max_f0 = float(np.max(valid_f0_values))
                
                combined_line_data['f0_curve'] = {
                    "color": "#FF6B6B",
                    "lineWidth": 3,
                    "yMin": 0,
                    "yMax": TOTAL_NOTES * NOTE_HEIGHT,
                    "position": "overlay",
                    "renderMode": "piano_grid",
                    "visible": True,
                    "opacity": 0.8,
                    "data": f0_points,
                    "dataType": "f0",
                    "unit": "Hz",
                    "originalRange": {
                        "minHz": min_f0,
                        "maxHz": max_f0,
                        "minMidi": hz_to_midi(min_f0),
                        "maxMidi": hz_to_midi(max_f0)
                    }
                }

        # Loudness ê³¡ì„  ì¶”ê°€
        if 'loudness' in features:
            loudness_data = features['loudness']
            times = loudness_data['times']
            loudness_db = loudness_data['loudness_db']

            loudness_points = []
            for time, value in zip(times, loudness_db):
                if not np.isnan(value):
                    x_pixel = time * (tempo / 60) * pixels_per_beat
                    # -60dB ~ 0dBë¥¼ 0 ~ 2560 í”½ì…€ë¡œ ë³€í™˜
                    normalized_value = (value + 60) / 60
                    y_pixel = normalized_value * 2560
                    loudness_points.append({"x": float(x_pixel), "y": float(max(0, min(2560, y_pixel)))})

            if loudness_points:
                combined_line_data['loudness_curve'] = {
                    "color": "#4ECDC4",
                    "lineWidth": 2,
                    "yMin": 0,
                    "yMax": 2560,
                    "position": "overlay",
                    "renderMode": "independent_range",
                    "visible": True,
                    "opacity": 0.6,
                    "data": loudness_points,
                    "dataType": "loudness",
                    "unit": "dB",
                    "originalRange": {
                        "min": float(np.min(loudness_db)),
                        "max": float(np.max(loudness_db)),
                        "y_min": -60,
                        "y_max": 0
                    }
                }

        # Voice/Unvoice ê³¡ì„  ì¶”ê°€
        if 'voicing' in features:
            voicing_data = features['voicing']
            times = voicing_data['times']
            voiced_probs = voicing_data['voiced_probs']

            voicing_points = []
            for time, value in zip(times, voiced_probs):
                if not np.isnan(value):
                    x_pixel = time * (tempo / 60) * pixels_per_beat
                    y_pixel = value * 2560  # 0-1ì„ 0-2560 í”½ì…€ë¡œ ë³€í™˜
                    voicing_points.append({"x": float(x_pixel), "y": float(max(0, min(2560, y_pixel)))})

            if voicing_points:
                combined_line_data['voicing_curve'] = {
                    "color": "#9B59B6",
                    "lineWidth": 2,
                    "yMin": 0,
                    "yMax": 2560,
                    "position": "overlay",
                    "renderMode": "independent_range",
                    "visible": True,
                    "opacity": 0.6,
                    "data": voicing_points,
                    "dataType": "voicing",
                    "unit": "probability",
                    "originalRange": {
                        "min": 0.0,
                        "max": 1.0,
                        "voiced_ratio": voicing_data.get('voiced_ratio', 0.0),
                        "y_min": 0,
                        "y_max": 1
                    }
                }

        return combined_line_data if combined_line_data else None

    except Exception as e:
        print(f"âŒ ê³¡ì„  ë°ì´í„° ìƒì„± ì˜¤ë¥˜: {e}")
        return None

def synthesize_and_analyze(piano_roll, attack, decay, sustain, release, wave_type, f0_method="pyin"):
    """ë…¸íŠ¸ì—ì„œ ì˜¤ë””ì˜¤ë¥¼ í•©ì„±í•˜ê³  íŠ¹ì„± ë¶„ì„"""
    global _last_synthesis_config, _synthesis_count
    
    # í˜„ì¬ ë¶„ì„ ì„¤ì •
    current_analysis_config = {
        'wave_type': wave_type,
        'attack': round(attack, 3),
        'decay': round(decay, 3),
        'sustain': round(sustain, 2), 
        'release': round(release, 3),
        'f0_method': f0_method
    }
    
    # ì„¤ì • ë³€ê²½ ì—¬ë¶€ í™•ì¸
    analysis_config_changed = (
        current_analysis_config.get('wave_type') != _last_synthesis_config.get('wave_type') or
        current_analysis_config.get('attack') != _last_synthesis_config.get('attack') or
        current_analysis_config.get('decay') != _last_synthesis_config.get('decay') or
        current_analysis_config.get('sustain') != _last_synthesis_config.get('sustain') or
        current_analysis_config.get('release') != _last_synthesis_config.get('release') or
        'f0_method' not in _last_synthesis_config or
        current_analysis_config.get('f0_method') != _last_synthesis_config.get('f0_method', 'pyin')
    )
    
    if analysis_config_changed or _synthesis_count <= 1:
        print("=" * 50)
        print("ğŸµ ì˜¤ë””ì˜¤ í•©ì„± ë° íŠ¹ì„± ë¶„ì„ ì‹œì‘")
        print(f"ğŸ“Š ì„ íƒëœ íŒŒí˜•: {wave_type}")
        print(f"ğŸ›ï¸ ADSR ì„¤ì •: A={attack:.3f}, D={decay:.3f}, S={sustain:.2f}, R={release:.3f}")
        print(f"ğŸ”¬ F0 ë¶„ì„ ë°©ë²•: {f0_method}")
    else:
        print("ğŸ”„ ë™ì¼ ì„¤ì •ìœ¼ë¡œ ì¬ë¶„ì„ ì‹œì‘")

    # 1. ì˜¤ë””ì˜¤ í•©ì„±
    audio_data = synthesize_audio(piano_roll, attack, decay, sustain, release, wave_type)
    if audio_data is None:
        print("âŒ ì˜¤ë””ì˜¤ í•©ì„± ì‹¤íŒ¨")
        return piano_roll, "ì˜¤ë””ì˜¤ í•©ì„± ì‹¤íŒ¨", None

    # 2. base64ë¡œ ë³€í™˜ (í”¼ì•„ë…¸ë¡¤ìš©)
    audio_base64 = audio_array_to_base64_wav(audio_data, SAMPLE_RATE)
    if audio_base64 and analysis_config_changed:
        print(f"ğŸ“¦ Base64 ë³€í™˜ ì™„ë£Œ: {len(audio_base64)} ë¬¸ì")

    # 3. ì„ì‹œ WAV íŒŒì¼ ìƒì„±
    temp_audio_path = create_temp_wav_file(audio_data, SAMPLE_RATE)
    if temp_audio_path is None:
        print("âŒ ì„ì‹œ WAV íŒŒì¼ ìƒì„± ì‹¤íŒ¨")
        return piano_roll, "ì„ì‹œ ì˜¤ë””ì˜¤ íŒŒì¼ ìƒì„± ì‹¤íŒ¨", None

    try:
        # 4. ì˜¤ë””ì˜¤ íŠ¹ì„± ë¶„ì„
        if LIBROSA_AVAILABLE:
            if analysis_config_changed:
                print("ğŸ” ì˜¤ë””ì˜¤ íŠ¹ì„± ë¶„ì„ ì‹œì‘...")
            features, analysis_status = extract_audio_features(
                temp_audio_path, f0_method, 
                include_f0=True, include_loudness=True, include_voicing=True
            )
        else:
            if analysis_config_changed:
                print("âš ï¸ librosa ë¯¸ì„¤ì¹˜ë¡œ íŠ¹ì„± ë¶„ì„ ìƒëµ")
            features = None
            analysis_status = "librosa ë¯¸ì„¤ì¹˜"

        # 5. í”¼ì•„ë…¸ë¡¤ ì—…ë°ì´íŠ¸
        updated_piano_roll = piano_roll.copy() if piano_roll else {}
        updated_piano_roll['audio_data'] = audio_base64
        updated_piano_roll['use_backend_audio'] = True

        # 6. ê³¡ì„  ë°ì´í„° ìƒì„± ë° ì¶”ê°€
        line_data = None
        if features:
            tempo = updated_piano_roll.get('tempo', 120)
            pixels_per_beat = updated_piano_roll.get('pixelsPerBeat', 80)
            
            line_data = create_multi_feature_line_data(features, tempo, pixels_per_beat)
            if line_data and analysis_config_changed:
                print(f"ğŸ“ˆ {len(line_data)}ê°œ íŠ¹ì„± ê³¡ì„  ìƒì„±ë¨")

        # 7. ìƒíƒœ ë©”ì‹œì§€ ìƒì„±
        status_parts = [
            f"âœ… {wave_type.upper()} íŒŒí˜•ìœ¼ë¡œ ì˜¤ë””ì˜¤ í•©ì„± ì™„ë£Œ",
            f"ADSR: A={attack:.3f} D={decay:.3f} S={sustain:.2f} R={release:.3f}",
            f"ê¸¸ì´: {len(audio_data)/SAMPLE_RATE:.2f}ì´ˆ"
        ]

        if features:
            status_parts.append(analysis_status)
            
            if line_data:
                curve_count = len(line_data)
                status_parts.append(f"{curve_count}ê°œ íŠ¹ì„± ê³¡ì„  ì‹œê°í™”")

        status_message = " | ".join(status_parts)
        
        if analysis_config_changed:
            print(f"ğŸ“‹ ìµœì¢… ìƒíƒœ: {status_message}")
            print("=" * 50)
        
        # f0_methodë¥¼ _last_synthesis_configì— ì €ì¥
        _last_synthesis_config['f0_method'] = f0_method

        return updated_piano_roll, status_message, temp_audio_path

    except Exception as e:
        error_message = f"íŠ¹ì„± ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"
        print(f"âŒ {error_message}")
        if analysis_config_changed:
            print("=" * 50)
        return piano_roll, error_message, temp_audio_path

def analyze_uploaded_audio_features(piano_roll, audio_file, include_f0=True, include_loudness=True, include_voicing=True, f0_method="pyin"):
    """ì—…ë¡œë“œëœ ì˜¤ë””ì˜¤ íŒŒì¼ì˜ íŠ¹ì„± ë¶„ì„"""
    print("=== ì—…ë¡œë“œëœ ì˜¤ë””ì˜¤ íŠ¹ì„± ë¶„ì„ ===")
    print(f"ì˜¤ë””ì˜¤ íŒŒì¼: {audio_file}")

    if not audio_file:
        return piano_roll, "ì˜¤ë””ì˜¤ íŒŒì¼ì„ ì—…ë¡œë“œí•´ ì£¼ì„¸ìš”.", None

    if not LIBROSA_AVAILABLE:
        return piano_roll, "librosaê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•„ ì˜¤ë””ì˜¤ íŠ¹ì„± ë¶„ì„ì„ ìˆ˜í–‰í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. 'pip install librosa'ë¡œ ì„¤ì¹˜í•´ ì£¼ì„¸ìš”.", None

    try:
        # ì˜¤ë””ì˜¤ íŠ¹ì„± ë¶„ì„
        features, analysis_status = extract_audio_features(
            audio_file, f0_method, include_f0, include_loudness, include_voicing
        )

        if features is None:
            return piano_roll, f"ì˜¤ë””ì˜¤ íŠ¹ì„± ë¶„ì„ ì‹¤íŒ¨: {analysis_status}", audio_file

        # í”¼ì•„ë…¸ë¡¤ ë°ì´í„° ì—…ë°ì´íŠ¸
        updated_piano_roll = piano_roll.copy() if piano_roll else {
            "notes": [],
            "tempo": 120,
            "timeSignature": {"numerator": 4, "denominator": 4},
            "editMode": "select",
            "snapSetting": "1/4",
            "pixelsPerBeat": 80
        }

        # ê³¡ì„  ë°ì´í„° ìƒì„±
        tempo = updated_piano_roll.get('tempo', 120)
        pixels_per_beat = updated_piano_roll.get('pixelsPerBeat', 80)

        line_data = create_multi_feature_line_data(features, tempo, pixels_per_beat)

        if line_data:
            updated_piano_roll['line_data'] = line_data

        # ìƒíƒœ ë©”ì‹œì§€ ìƒì„±
        status_parts = [analysis_status]

        if line_data:
            curve_count = len(line_data)
            curve_types = list(line_data.keys())
            status_parts.append(f"{curve_count}ê°œ ê³¡ì„  ({', '.join(curve_types)}) ì‹œê°í™” ì™„ë£Œ")

            # ê° íŠ¹ì„± ë²”ìœ„ ì •ë³´ ì¶”ê°€
            for curve_name, curve_info in line_data.items():
                if 'originalRange' in curve_info:
                    range_info = curve_info['originalRange']
                    if 'minHz' in range_info:  # F0
                        status_parts.append(f"F0: {range_info['minHz']:.1f}~{range_info['maxHz']:.1f}Hz")
                    elif 'min' in range_info and 'voiced_ratio' not in range_info:  # Loudness
                        unit = curve_info.get('unit', '')
                        status_parts.append(f"Loudness: {range_info['min']:.1f}~{range_info['max']:.1f}{unit}")
                    elif 'voiced_ratio' in range_info:  # Voice/Unvoice
                        voiced_ratio = range_info['voiced_ratio']
                        status_parts.append(f"Voicing: {voiced_ratio:.1%} voiced")

        duration = features.get('duration', 0)
        status_parts.append(f"â±ï¸ {duration:.2f}ì´ˆ")

        status_message = " | ".join(status_parts)

        return updated_piano_roll, status_message, audio_file

    except Exception as e:
        error_message = f"ì—…ë¡œë“œëœ ì˜¤ë””ì˜¤ ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"
        print(f"âŒ {error_message}")
        return piano_roll, error_message, audio_file

# Gradio ì¸í„°í˜ì´ìŠ¤
with gr.Blocks(title="PianoRoll Comprehensive Demo") as demo:
    gr.Markdown("# ğŸ¹ PianoRoll Comprehensive Demo")
    gr.Markdown("ë…¸íŠ¸ë¥¼ í¸ì§‘í•˜ê³  ì˜¤ë””ì˜¤ë¥¼ í•©ì„±í•œ í›„ íŠ¹ì„±ì„ ë¶„ì„í•˜ê±°ë‚˜, ì˜¤ë””ì˜¤ íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì—¬ ë¶„ì„í•´ë³´ì„¸ìš”!")

    with gr.Row():
        with gr.Column(scale=3):
            # ì´ˆê¸°ê°’ (ìƒ˜í”Œ ë…¸íŠ¸)
            initial_value = {
                "notes": [
                    {
                        "start": 0,
                        "duration": 160,
                        "pitch": 60,  # C4
                        "velocity": 100,
                        "lyric": "ë„"
                    },
                    {
                        "start": 160,
                        "duration": 160,
                        "pitch": 62,  # D4
                        "velocity": 100,
                        "lyric": "ë ˆ"
                    },
                    {
                        "start": 320,
                        "duration": 160,
                        "pitch": 64,  # E4
                        "velocity": 100,
                        "lyric": "ë¯¸"
                    },
                    {
                        "start": 480,
                        "duration": 160,
                        "pitch": 65,  # F4
                        "velocity": 100,
                        "lyric": "íŒŒ"
                    }
                ],
                "tempo": 120,
                "timeSignature": {"numerator": 4, "denominator": 4},
                "editMode": "select",
                "snapSetting": "1/4",
                "pixelsPerBeat": 80
            }
            piano_roll = PianoRoll(
                height=600,
                width=1000,
                value=initial_value,
                elem_id="piano_roll_main"
            )

        with gr.Column(scale=1):
            gr.Markdown("### ğŸ›ï¸ ì˜¤ë””ì˜¤ í•©ì„± ì„¤ì •")
            
            # ADSR ì„¤ì •
            gr.Markdown("**ADSR ì—”ë²¨ë¡œí”„**")
            attack_slider = gr.Slider(
                minimum=0.001,
                maximum=1.0,
                value=0.01,
                step=0.001,
                label="Attack (ì´ˆ)"
            )
            decay_slider = gr.Slider(
                minimum=0.001,
                maximum=1.0,
                value=0.1,
                step=0.001,
                label="Decay (ì´ˆ)"
            )
            sustain_slider = gr.Slider(
                minimum=0.0,
                maximum=1.0,
                value=0.7,
                step=0.01,
                label="Sustain (ë ˆë²¨)"
            )
            release_slider = gr.Slider(
                minimum=0.001,
                maximum=2.0,
                value=0.3,
                step=0.001,
                label="Release (ì´ˆ)"
            )

            # íŒŒí˜• ì„¤ì •
            gr.Markdown("**íŒŒí˜• íƒ€ì…**")
            wave_type_dropdown = gr.Dropdown(
                choices=[
                    ("ë³µí•© íŒŒí˜• (Complex)", "complex"),
                    ("í•˜ëª¨ë‹‰ í•©ì„± (Harmonic)", "harmonic"),
                    ("FM í•©ì„± (FM)", "fm"),
                    ("í†±ë‹ˆíŒŒ (Sawtooth)", "sawtooth"),
                    ("ì‚¬ê°íŒŒ (Square)", "square"),
                    ("ì‚¼ê°íŒŒ (Triangle)", "triangle"),
                    ("ì‚¬ì¸íŒŒ (Sine)", "sine")
                ],
                value="complex",
                label="íŒŒí˜• íƒ€ì…"
            )

            # F0 ì¶”ì¶œ ë°©ë²•
            gr.Markdown("**íŠ¹ì„± ë¶„ì„ ì„¤ì •**")
            f0_method_dropdown = gr.Dropdown(
                choices=[
                    ("PYIN (ì •í™•, ëŠë¦¼)", "pyin"),
                    ("PipTrack (ë¹ ë¦„, ë¶€ì •í™•)", "piptrack")
                ],
                value="pyin",
                label="F0 ì¶”ì¶œ ë°©ë²•"
            )

            # ë²„íŠ¼ë“¤
            btn_synthesize = gr.Button(
                "ğŸ¶ ë…¸íŠ¸ í•©ì„± + íŠ¹ì„± ë¶„ì„",
                variant="primary",
                size="lg"
            )

    with gr.Row():
        # ì˜¤ë””ì˜¤ ì—…ë¡œë“œ 
        gr.Markdown("### ğŸ¤ ì˜¤ë””ì˜¤ íŒŒì¼ ë¶„ì„")
        
    with gr.Row():
        with gr.Column(scale=2):
            audio_input = gr.Audio(
                label="ë¶„ì„í•  ì˜¤ë””ì˜¤ íŒŒì¼",
                type="filepath",
                interactive=True
            )
        with gr.Column(scale=1):
            btn_analyze_uploaded = gr.Button(
                "ğŸ”¬ ì—…ë¡œë“œ íŒŒì¼ ë¶„ì„",
                variant="secondary",
                interactive=LIBROSA_AVAILABLE
            )

    with gr.Row():
        status_text = gr.Textbox(
            label="ìƒíƒœ",
            interactive=False,
            lines=3
        )

    with gr.Row():
        reference_audio = gr.Audio(
            label="ìƒì„±/ì›ë³¸ ì˜¤ë””ì˜¤ (ì°¸ì¡°ìš©)",
            type="filepath",
            interactive=False
        )

    output_json = gr.JSON(label="í”¼ì•„ë…¸ë¡¤ ë°ì´í„°")

    # ì´ë²¤íŠ¸ ì²˜ë¦¬
    btn_synthesize.click(
        fn=synthesize_and_analyze,
        inputs=[
            piano_roll,
            attack_slider,
            decay_slider,
            sustain_slider,
            release_slider,
            wave_type_dropdown,
            f0_method_dropdown
        ],
        outputs=[piano_roll, status_text, reference_audio],
        show_progress=True
    )
    
    btn_analyze_uploaded.click(
        fn=analyze_uploaded_audio_features,
        inputs=[piano_roll, audio_input, f0_method_dropdown],
        outputs=[piano_roll, status_text, reference_audio],
        show_progress=True
    )

    # JSON ì¶œë ¥ ì—…ë°ì´íŠ¸
    piano_roll.change(
        fn=lambda x: x,
        inputs=[piano_roll],
        outputs=[output_json],
        show_progress=False
    )

if __name__ == "__main__":
    demo.launch() 