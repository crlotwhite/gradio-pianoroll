# ì˜¤ë””ì˜¤ íŠ¹ì„± ì¢…í•© ë¶„ì„

F0, ìŒëŸ‰, ìŒì„± ê°ì§€ ë“± ë‹¤ì–‘í•œ ì˜¤ë””ì˜¤ íŠ¹ì„±ì„ ë¶„ì„í•˜ê³  PianoRollì—ì„œ ì‹œê°í™”í•˜ëŠ” ë°©ë²•ì„ ì„¤ëª…í•©ë‹ˆë‹¤.

## ê°œìš”

gradio-pianorollì€ librosaë¥¼ í™œìš©í•˜ì—¬ ì˜¤ë””ì˜¤ì˜ ë‹¤ì–‘í•œ íŠ¹ì„±ì„ ì¶”ì¶œí•˜ê³  ì´ë¥¼ í”¼ì•„ë…¸ë¡¤ì—ì„œ ì¢…í•©ì ìœ¼ë¡œ ì‹œê°í™”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

## ê¸°ë³¸ ì˜¤ë””ì˜¤ íŠ¹ì„± ë¶„ì„

```python
import gradio as gr
import librosa
import numpy as np
from gradio_pianoroll import PianoRoll
from gradio_pianoroll.audio_utils import (
    librosa_f0_to_pixels,
    librosa_rms_to_pixels,
    create_loudness_curve_data
)

def comprehensive_audio_analysis(audio_file):
    """ì˜¤ë””ì˜¤ íŒŒì¼ì˜ ì¢…í•©ì  íŠ¹ì„± ë¶„ì„"""
    if audio_file is None:
        return None, "ì˜¤ë””ì˜¤ íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”."

    try:
        # ì˜¤ë””ì˜¤ ë¡œë“œ
        y, sr = librosa.load(audio_file, sr=22050)

        # 1. F0 (ê¸°ë³¸ ì£¼íŒŒìˆ˜) ë¶„ì„
        f0, voiced_flag, voiced_probs = librosa.pyin(
            y, fmin=librosa.note_to_hz('C2'), fmax=librosa.note_to_hz('C7')
        )

        # 2. RMS (ìŒëŸ‰) ë¶„ì„
        rms = librosa.feature.rms(y=y, frame_length=2048, hop_length=512)[0]

        # 3. ìŠ¤í™íŠ¸ëŸ´ ì„¼íŠ¸ë¡œì´ë“œ (ìŒìƒ‰ ë°ê¸°)
        spectral_centroids = librosa.feature.spectral_centroid(y=y, sr=sr)[0]

        # 4. ì˜í¬ë¡œì‹±ë¥  (ìŒì„±/ë¹„ìŒì„± êµ¬ë¶„)
        zcr = librosa.feature.zero_crossing_rate(y)[0]

        # 5. ë©œ ì£¼íŒŒìˆ˜ ì¼‘ìŠ¤íŠ¸ëŸ´ ê³„ìˆ˜ (ìŒìƒ‰ íŠ¹ì„±)
        mfccs = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=13)

        # í”¼ì•„ë…¸ë¡¤ìš© ê³¡ì„  ë°ì´í„° ìƒì„±
        curves = {}

        # F0 ê³¡ì„ 
        if np.any(~np.isnan(f0)):
            curves['f0'] = librosa_f0_to_pixels(f0, sr=sr)

        # ìŒëŸ‰ ê³¡ì„ 
        curves['loudness'] = librosa_rms_to_pixels(rms, sr=sr)

        # ìŒì„± í™•ë¥  ê³¡ì„ 
        if voiced_probs is not None:
            curves['voicing'] = librosa_rms_to_pixels(voiced_probs, sr=sr)

        # ë¶„ì„ ê²°ê³¼ ìš”ì•½
        analysis_summary = create_analysis_summary(
            f0, rms, spectral_centroids, zcr, mfccs, sr
        )

        return curves, analysis_summary

    except Exception as e:
        return None, f"ì˜¤ë¥˜ ë°œìƒ: {str(e)}"

def create_analysis_summary(f0, rms, spectral_centroids, zcr, mfccs, sr):
    """ë¶„ì„ ê²°ê³¼ ìš”ì•½ ìƒì„±"""
    # ìœ íš¨í•œ F0 ê°’ë“¤
    valid_f0 = f0[~np.isnan(f0)]

    summary = f"""
    ğŸµ ì˜¤ë””ì˜¤ íŠ¹ì„± ë¶„ì„ ê²°ê³¼:

    ğŸ“Š ê¸°ë³¸ ì£¼íŒŒìˆ˜ (F0):
    - í‰ê· : {np.mean(valid_f0):.2f} Hz
    - ë²”ìœ„: {np.min(valid_f0):.2f} - {np.max(valid_f0):.2f} Hz
    - í‘œì¤€í¸ì°¨: {np.std(valid_f0):.2f} Hz

    ğŸ”Š ìŒëŸ‰ (RMS):
    - í‰ê· : {np.mean(rms):.4f}
    - ìµœëŒ€: {np.max(rms):.4f}
    - ë™ì  ë²”ìœ„: {20 * np.log10(np.max(rms) / np.mean(rms)):.2f} dB

    ğŸ¶ ìŒìƒ‰ íŠ¹ì„±:
    - ìŠ¤í™íŠ¸ëŸ´ ì„¼íŠ¸ë¡œì´ë“œ í‰ê· : {np.mean(spectral_centroids):.2f} Hz
    - ì˜í¬ë¡œì‹±ë¥  í‰ê· : {np.mean(zcr):.4f}
    - MFCC ì²« ë²ˆì§¸ ê³„ìˆ˜: {np.mean(mfccs[0]):.2f}

    ğŸ“ˆ ì˜¤ë””ì˜¤ ê¸¸ì´: {len(f0) * 512 / sr:.2f}ì´ˆ
    """

    return summary

with gr.Blocks() as demo:
    gr.Markdown("# ì˜¤ë””ì˜¤ íŠ¹ì„± ì¢…í•© ë¶„ì„")

    with gr.Row():
        with gr.Column():
            audio_input = gr.Audio(
                label="ë¶„ì„í•  ì˜¤ë””ì˜¤ íŒŒì¼",
                type="filepath"
            )
            analyze_btn = gr.Button("ì¢…í•© ë¶„ì„ ì‹œì‘", variant="primary")

        with gr.Column():
            analysis_result = gr.Textbox(
                label="ë¶„ì„ ê²°ê³¼ ìš”ì•½",
                lines=15,
                interactive=False
            )

    piano_roll = PianoRoll(
        label="ì˜¤ë””ì˜¤ íŠ¹ì„± ì‹œê°í™”",
        height=500,
        width=1000
    )

    analyze_btn.click(
        fn=comprehensive_audio_analysis,
        inputs=audio_input,
        outputs=[piano_roll, analysis_result]
    )

if __name__ == "__main__":
    demo.launch()
```

## ê³ ê¸‰ íŠ¹ì„± ë¶„ì„

### í•˜ëª¨ë‹‰-í¼ì»¤ì‹œë¸Œ ë¶„ë¦¬

```python
def harmonic_percussive_analysis(audio_file):
    """í•˜ëª¨ë‹‰ê³¼ í¼ì»¤ì‹œë¸Œ ì„±ë¶„ ë¶„ë¦¬ ë¶„ì„"""
    y, sr = librosa.load(audio_file, sr=22050)

    # í•˜ëª¨ë‹‰-í¼ì»¤ì‹œë¸Œ ë¶„ë¦¬
    y_harmonic, y_percussive = librosa.effects.hpss(y)

    # ê° ì„±ë¶„ë³„ íŠ¹ì„± ë¶„ì„
    harmonic_features = {
        'f0': librosa.pyin(y_harmonic, fmin=80, fmax=400)[0],
        'rms': librosa.feature.rms(y=y_harmonic)[0],
        'spectral_centroid': librosa.feature.spectral_centroid(y=y_harmonic, sr=sr)[0]
    }

    percussive_features = {
        'rms': librosa.feature.rms(y=y_percussive)[0],
        'zcr': librosa.feature.zero_crossing_rate(y_percussive)[0],
        'tempo': librosa.beat.tempo(y=y_percussive, sr=sr)
    }

    return harmonic_features, percussive_features
```

### ìŒì„± í™œë™ ê°ì§€

```python
def voice_activity_detection(audio_file, threshold=0.02):
    """ìŒì„± í™œë™ êµ¬ê°„ ê°ì§€"""
    y, sr = librosa.load(audio_file, sr=22050)

    # RMS ì—ë„ˆì§€ ê³„ì‚°
    rms = librosa.feature.rms(y=y, frame_length=2048, hop_length=512)[0]

    # ì„ê³„ê°’ ê¸°ë°˜ ìŒì„± í™œë™ ê°ì§€
    voice_activity = rms > threshold

    # ì—°ì†ëœ ìŒì„± êµ¬ê°„ ì°¾ê¸°
    voice_segments = []
    in_voice = False
    start_frame = 0

    for i, is_voice in enumerate(voice_activity):
        if is_voice and not in_voice:
            # ìŒì„± ì‹œì‘
            start_frame = i
            in_voice = True
        elif not is_voice and in_voice:
            # ìŒì„± ì¢…ë£Œ
            end_frame = i
            start_time = start_frame * 512 / sr
            end_time = end_frame * 512 / sr
            voice_segments.append((start_time, end_time))
            in_voice = False

    # ë§ˆì§€ë§‰ êµ¬ê°„ ì²˜ë¦¬
    if in_voice:
        end_time = len(voice_activity) * 512 / sr
        start_time = start_frame * 512 / sr
        voice_segments.append((start_time, end_time))

    return voice_segments, voice_activity
```

### ë©œë¡œë”” ì¶”ì¶œ

```python
def extract_melody_line(audio_file):
    """ì£¼ ë©œë¡œë”” ë¼ì¸ ì¶”ì¶œ"""
    y, sr = librosa.load(audio_file, sr=22050)

    # í•˜ëª¨ë‹‰ ì„±ë¶„ ì¶”ì¶œ
    y_harmonic, _ = librosa.effects.hpss(y)

    # F0 ì¶”ì¶œ
    f0, voiced_flag, voiced_probs = librosa.pyin(
        y_harmonic,
        fmin=librosa.note_to_hz('C3'),
        fmax=librosa.note_to_hz('C6'),
        threshold=0.1
    )

    # ë©œë¡œë”” ìŠ¤ë¬´ë”©
    from scipy import ndimage
    smoothed_f0 = np.copy(f0)
    valid_indices = ~np.isnan(f0)
    smoothed_f0[valid_indices] = ndimage.gaussian_filter1d(
        f0[valid_indices], sigma=2
    )

    # ë…¸íŠ¸ ì„¸ê·¸ë©˜í…Œì´ì…˜
    melody_notes = []
    current_pitch = None
    current_start = None
    pitch_tolerance = 50  # Hz

    for i, freq in enumerate(smoothed_f0):
        if np.isnan(freq):
            # ë¬´ìŒ êµ¬ê°„
            if current_pitch is not None:
                # í˜„ì¬ ë…¸íŠ¸ ì¢…ë£Œ
                duration = (i - current_start) * 512 / sr
                melody_notes.append({
                    'pitch': librosa.hz_to_midi(current_pitch),
                    'start': current_start * 512 / sr,
                    'duration': duration,
                    'frequency': current_pitch
                })
                current_pitch = None
        else:
            if current_pitch is None:
                # ìƒˆ ë…¸íŠ¸ ì‹œì‘
                current_pitch = freq
                current_start = i
            else:
                # í”¼ì¹˜ ë³€í™” í™•ì¸
                if abs(freq - current_pitch) > pitch_tolerance:
                    # í”¼ì¹˜ê°€ í¬ê²Œ ë³€í–ˆìœ¼ë¯€ë¡œ ìƒˆ ë…¸íŠ¸
                    duration = (i - current_start) * 512 / sr
                    melody_notes.append({
                        'pitch': librosa.hz_to_midi(current_pitch),
                        'start': current_start * 512 / sr,
                        'duration': duration,
                        'frequency': current_pitch
                    })
                    current_pitch = freq
                    current_start = i

    return melody_notes, smoothed_f0
```

## ì‹¤ì‹œê°„ íŠ¹ì„± ë¶„ì„

### ìŠ¤íŠ¸ë¦¬ë° ì˜¤ë””ì˜¤ ë¶„ì„

```python
class RealTimeAudioAnalyzer:
    def __init__(self, sr=22050, hop_length=512):
        self.sr = sr
        self.hop_length = hop_length
        self.buffer = []
        self.features_history = []

    def process_chunk(self, audio_chunk):
        """ì˜¤ë””ì˜¤ ì²­í¬ ì²˜ë¦¬"""
        self.buffer.extend(audio_chunk)

        # ì¶©ë¶„í•œ ë°ì´í„°ê°€ ëª¨ì´ë©´ ë¶„ì„
        if len(self.buffer) >= 2048:
            y = np.array(self.buffer[-2048:])

            # ì‹¤ì‹œê°„ íŠ¹ì„± ì¶”ì¶œ
            features = self.extract_features(y)
            self.features_history.append(features)

            # íˆìŠ¤í† ë¦¬ í¬ê¸° ì œí•œ
            if len(self.features_history) > 100:
                self.features_history = self.features_history[-100:]

            return features

    def extract_features(self, y):
        """ì˜¤ë””ì˜¤ íŠ¹ì„± ì¶”ì¶œ"""
        features = {}

        # RMS ì—ë„ˆì§€
        rms = np.sqrt(np.mean(y**2))
        features['rms'] = rms

        # ì˜í¬ë¡œì‹±ë¥ 
        zcr = np.mean(librosa.feature.zero_crossing_rate(y))
        features['zcr'] = zcr

        # ìŠ¤í™íŠ¸ëŸ´ ì„¼íŠ¸ë¡œì´ë“œ
        if len(y) > 512:
            spectral_centroid = np.mean(
                librosa.feature.spectral_centroid(y=y, sr=self.sr)
            )
            features['spectral_centroid'] = spectral_centroid

        return features
```

### ì ì‘í˜• ë¶„ì„ íŒŒë¼ë¯¸í„°

```python
def adaptive_analysis_parameters(audio_file):
    """ì˜¤ë””ì˜¤ íŠ¹ì„±ì— ë”°ë¼ ë¶„ì„ íŒŒë¼ë¯¸í„° ìë™ ì¡°ì •"""
    y, sr = librosa.load(audio_file, sr=22050)

    # ê¸°ë³¸ íŠ¹ì„± ë¶„ì„
    rms = librosa.feature.rms(y=y)[0]
    zcr = librosa.feature.zero_crossing_rate(y)[0]

    # ì˜¤ë””ì˜¤ íƒ€ì… ì¶”ì •
    avg_rms = np.mean(rms)
    avg_zcr = np.mean(zcr)

    if avg_zcr > 0.1:
        # ë…¸ì´ì¦ˆê°€ ë§ì€ ì‹ í˜¸ - ë” ì—„ê²©í•œ ì„ê³„ê°’
        audio_type = "noisy"
        f0_threshold = 0.3
        fmin, fmax = 80, 400
    elif avg_rms < 0.01:
        # ì¡°ìš©í•œ ì‹ í˜¸ - ë¯¼ê°í•œ ì„ê³„ê°’
        audio_type = "quiet"
        f0_threshold = 0.05
        fmin, fmax = 50, 800
    else:
        # ì¼ë°˜ì ì¸ ì‹ í˜¸
        audio_type = "normal"
        f0_threshold = 0.1
        fmin, fmax = librosa.note_to_hz('C2'), librosa.note_to_hz('C7')

    # ì ì‘í˜• F0 ë¶„ì„
    f0, voiced_flag, voiced_probs = librosa.pyin(
        y, fmin=fmin, fmax=fmax, threshold=f0_threshold
    )

    return f0, audio_type, {
        'threshold': f0_threshold,
        'fmin': fmin,
        'fmax': fmax
    }
```

## ë‹¤ì¤‘ ê³¡ì„  ì‹œê°í™”

### ì—¬ëŸ¬ íŠ¹ì„±ì„ ë™ì‹œì— í‘œì‹œ

```python
def multi_feature_visualization(audio_file):
    """ì—¬ëŸ¬ ì˜¤ë””ì˜¤ íŠ¹ì„±ì„ í•˜ë‚˜ì˜ í”¼ì•„ë…¸ë¡¤ì— ì‹œê°í™”"""
    y, sr = librosa.load(audio_file, sr=22050)

    # ë‹¤ì–‘í•œ íŠ¹ì„± ì¶”ì¶œ
    f0, _, voiced_probs = librosa.pyin(y, fmin=80, fmax=400)
    rms = librosa.feature.rms(y=y)[0]
    spectral_centroid = librosa.feature.spectral_centroid(y=y, sr=sr)[0]

    # ì •ê·œí™” (0-1 ë²”ìœ„ë¡œ)
    def normalize_feature(feature):
        valid_values = feature[~np.isnan(feature)]
        if len(valid_values) == 0:
            return feature
        min_val, max_val = np.min(valid_values), np.max(valid_values)
        normalized = (feature - min_val) / (max_val - min_val)
        return normalized

    # í”¼ì•„ë…¸ë¡¤ìš© ê³¡ì„  ë°ì´í„° ìƒì„±
    curves = {}

    # F0 ê³¡ì„  (íŒŒë€ìƒ‰)
    if np.any(~np.isnan(f0)):
        curves['pitch'] = librosa_f0_to_pixels(f0, sr=sr)

    # ìŒëŸ‰ ê³¡ì„  (ë¹¨ê°„ìƒ‰) - ë‚®ì€ ìœ„ì¹˜ì— í‘œì‹œ
    normalized_rms = normalize_feature(rms) * 200 + 100  # í•˜ë‹¨ ì˜ì—­
    curves['loudness'] = create_loudness_curve_data(normalized_rms, sr=sr)

    # ìŒìƒ‰ ë°ê¸° ê³¡ì„  (ì´ˆë¡ìƒ‰) - ì¤‘ê°„ ìœ„ì¹˜ì— í‘œì‹œ
    normalized_centroid = normalize_feature(spectral_centroid) * 200 + 800  # ì¤‘ê°„ ì˜ì—­
    curves['brightness'] = create_loudness_curve_data(normalized_centroid, sr=sr)

    return curves
```

## ì°¸ê³  ìë£Œ

- [Librosa íŠ¹ì„± ì¶”ì¶œ ë¬¸ì„œ](https://librosa.org/doc/main/feature.html)
- [F0 ë¶„ì„ ìƒì„¸ ê°€ì´ë“œ](f0-analysis.md)
- [í”¼ì•„ë…¸ë¡¤ ê¸°ë³¸ ì‚¬ìš©ë²•](basic-usage.md)

## ë‹¤ìŒ ë‹¨ê³„

- [ì‹¤ì‹œê°„ ì˜¤ë””ì˜¤ ì²˜ë¦¬](../user-guide/audio-analysis.md)
- [ìŒì„± í•©ì„± ì—°ë™](synthesizer.md)
- [ê³ ê¸‰ ì‹ í˜¸ ì²˜ë¦¬](../advanced/performance.md)