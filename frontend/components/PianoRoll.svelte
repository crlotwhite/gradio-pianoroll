<!--
  Main PianoRoll component that integrates all subcomponents.
  This component serves as the container for the entire piano roll interface.
  Now with playback functionality using Flicks timing, waveform visualization, and playhead.
-->
<script lang="ts">
  import { onMount, onDestroy } from 'svelte';
  import Toolbar from './Toolbar.svelte';
  import KeyboardComponent from './KeyboardComponent.svelte';
  import GridComponent from './GridComponent.svelte';
  import TimeLineComponent from './TimeLineComponent.svelte';
  import PlayheadComponent from './PlayheadComponent.svelte';
  import DebugComponent from './DebugComponent.svelte';
  import { AudioEngineManager } from '../utils/audioEngine';
  import { BackendAudioEngine } from '../utils/backendAudioEngine';
  import { beatsToFlicks, flicksToBeats, formatFlicks } from '../utils/flicks';
  import { createEventDispatcher } from 'svelte';
  /**
   * @typedef {import('../../types/component').PianoRollProps} PianoRollProps
   */

  // Ïù¥Î≤§Ìä∏ ÎîîÏä§Ìå®Ï≤ò ÏÉùÏÑ±
  const dispatch = createEventDispatcher();

  // Props (Ïô∏Î∂ÄÏóêÏÑú Ï£ºÏûÖÎêòÎäî Í∞í)
  /** @type {number} */
  export let width = 1000;  // Total width of the piano roll
  /** @type {number} */
  export let height = 600;  // Total height of the piano roll
  /** @type {number} */
  export let keyboardWidth = 120; // Width of the keyboard component
  /** @type {number} */
  export let timelineHeight = 40; // Height of the timeline component
  /** @type {string} */
  export let elem_id = '';  // Ïª¥Ìè¨ÎÑåÌä∏ Í≥†Ïú† ID

  /** @type {string | null} */
  export let audio_data: string | null = null;
  /** @type {object | null} */
  export let curve_data: object | null = null;
  /** @type {object | null} */
  export let line_data: object | null = null;  // Line layer data
  /** @type {boolean} */
  export let use_backend_audio: boolean = false;

  /** @type {Array<PianoRollProps['notes'][0]>} */
  export let notes: Array<{
    id: string,
    start: number,
    duration: number,
    startFlicks?: number,      // Optional for backward compatibility
    durationFlicks?: number,   // Optional for backward compatibility
    startSeconds?: number,     // Optional - seconds timing
    durationSeconds?: number,  // Optional - seconds timing
    endSeconds?: number,       // Optional - end time in seconds
    startBeats?: number,       // Optional - beats timing
    durationBeats?: number,    // Optional - beats timing
    startTicks?: number,       // Optional - MIDI ticks timing
    durationTicks?: number,    // Optional - MIDI ticks timing
    startSample?: number,      // Optional - sample timing
    durationSamples?: number,  // Optional - sample timing
    pitch: number,
    velocity: number,
    lyric?: string,
    phoneme?: string
  }> = [];

  // Settings
  /** @type {number} */
  export let tempo = 120;
  /** @type {{ numerator: number, denominator: number }} */
  export let timeSignature = { numerator: 4, denominator: 4 };
  /** @type {string} */
  export let editMode = 'select'; // 'select', 'draw', 'erase', etc.
  /** @type {string} */
  export let snapSetting = '1/4'; // Default snap setting: 1/4

  // Audio metadata
  /** @type {number} */
  export let sampleRate = 44100; // Audio sample rate
  /** @type {number} */
  export let ppqn = 480;         // MIDI pulses per quarter note

  // Zoom level (pixels per beat) - now controlled from parent
  /** @type {number} */
  export let pixelsPerBeat = 80;
  const MIN_PIXELS_PER_BEAT = 40; // Minimum zoom level
  const MAX_PIXELS_PER_BEAT = 200; // Maximum zoom level
  const ZOOM_STEP = 20; // Zoom step size (must be integer to avoid coordinate calculation errors)

  // Zoom in function
  function zoomIn() {
    if (pixelsPerBeat < MAX_PIXELS_PER_BEAT) {
      pixelsPerBeat += ZOOM_STEP;
      dispatchDataChange();
    }
  }

  // Zoom out function
  function zoomOut() {
    if (pixelsPerBeat > MIN_PIXELS_PER_BEAT) {
      pixelsPerBeat -= ZOOM_STEP;
      dispatchDataChange();
    }
  }

  // State variables (ÎÇ¥Î∂Ä ÏÉÅÌÉú)
  // Playback state
  let isPlaying = false;
  let isRendering = false;
  let currentFlicks = 0;

  // Scroll positions
  let horizontalScroll = 0;
  let verticalScroll = 0;

  // References to DOM elements
  let containerElement: HTMLDivElement;

  // Ïª¥Ìè¨ÎÑåÌä∏Î≥Ñ Ïò§ÎîîÏò§ ÏóîÏßÑ Ïù∏Ïä§ÌÑ¥Ïä§
  $: audioEngine = AudioEngineManager.getInstance(elem_id || 'default');
  // Backend audio engine Ïù∏Ïä§ÌÑ¥Ïä§
  const backendAudioEngine = new BackendAudioEngine();

  // Ï†ÑÏ≤¥ Îç∞Ïù¥ÌÑ∞ Î≥ÄÍ≤Ω Ïù¥Î≤§Ìä∏ Î∞úÏÉù
  function dispatchDataChange() {
    dispatch('dataChange', {
      notes,
      tempo,
      timeSignature,
      editMode,
      snapSetting,
      pixelsPerBeat,
      sampleRate,
      ppqn
    });
  }

  // ÎÖ∏Ìä∏Îßå Î≥ÄÍ≤Ω Ïù¥Î≤§Ìä∏ Î∞úÏÉù
  function dispatchNoteChange() {
    dispatch('noteChange', {
      notes
    });
  }

  // Sync scroll handlers
  function handleGridScroll(event: CustomEvent) {
    horizontalScroll = event.detail.horizontalScroll;
    verticalScroll = event.detail.verticalScroll;
    console.log('üé® PianoRoll: scroll received, verticalScroll =', verticalScroll);
    // The scroll values are now reactively bound to the other components
    // and will trigger updates when they change
  }

  // Settings handlers
  function handleTimeSignatureChange(event: CustomEvent) {
    timeSignature = event.detail;
    dispatchDataChange();
  }

  function handleEditModeChange(event: CustomEvent) {
    editMode = event.detail;
    dispatchDataChange();
  }

  function handleSnapChange(event: CustomEvent) {
    snapSetting = event.detail;
    dispatchDataChange();
  }

  // Handle zoom changes from toolbar
  function handleZoomChange(event: CustomEvent) {
    const { action } = event.detail;
    if (action === 'zoom-in') {
      zoomIn();
    } else if (action === 'zoom-out') {
      zoomOut();
    }
  }

  // Calculate total length in beats
  $: totalLengthInBeats = 32 * timeSignature.numerator; // 32 measures

  // Playback control functions
  async function renderAudio() {
    // Î∞±ÏóîÎìú Ïò§ÎîîÏò§Î•º ÏÇ¨Ïö©ÌïòÎäî Í≤ΩÏö∞ Î†åÎçîÎßÅÌïòÏßÄ ÏïäÏùå
    if (use_backend_audio) {
      console.log("üéµ Backend audio enabled - skipping frontend rendering");
      return;
    }

    // console.log("üéµ Frontend audio rendering started");
    isRendering = true;
    try {
      // Initialize component-specific audio engine
      audioEngine.initialize();

      // Render the notes to an audio buffer
      // Pass pixelsPerBeat to ensure proper alignment between waveform and notes
      await audioEngine.renderNotes(notes, tempo, totalLengthInBeats, pixelsPerBeat);

      // console.log("‚úÖ Frontend audio rendering completed");
      // Waveform is now updated through layer system automatically
    } catch (error) {
      console.error('Error rendering audio:', error);
    } finally {
      isRendering = false;
    }
  }

  // Í∏∞Ï°¥ backendAudioContext, backendAudioBuffer, backendAudioSource, backendPlayStartTime, backendPlayheadInterval Îì± ÏÉÅÌÉú Ï†úÍ±∞

  // Í∏∞Ï°¥ initBackendAudio, decodeBackendAudio, startBackendAudioPlayback, pauseBackendAudio, stopBackendAudio, updateBackendPlayhead, downloadBackendAudio Ìï®Ïàò Ï†úÍ±∞

  // Í∏∞Ï°¥ Ìï®Ïàò ÎåÄÏ≤¥
  async function handleBackendAudioInit() {
    if (audio_data) {
      await backendAudioEngine.initBackendAudio();
      await backendAudioEngine.decodeBackendAudio(audio_data);
    }
  }

  function handleBackendAudioPlay() {
    backendAudioEngine.startBackendAudioPlayback(currentFlicks, () => {
      isPlaying = false;
    });
  }

  function handleBackendAudioPause() {
    backendAudioEngine.pauseBackendAudio({ value: currentFlicks });
    isPlaying = false;
  }

  function handleBackendAudioStop() {
    backendAudioEngine.stopBackendAudio({ value: currentFlicks });
    isPlaying = false;
    currentFlicks = 0;
  }

  async function handleBackendAudioDownload() {
    if (audio_data) {
      await backendAudioEngine.downloadBackendAudio(audio_data);
    }
  }

  // Zoom level Î≥ÄÍ≤Ω Ïãú Ï†ÑÏ≤¥ Îç∞Ïù¥ÌÑ∞ Î≥ÄÍ≤Ω Ïù¥Î≤§Ìä∏ Î∞úÏÉù
  $: if (pixelsPerBeat) {
    dispatchDataChange();
  }

  // Playback control functions
  async function play() {
    if (isPlaying) {
      console.log("‚ö†Ô∏è Already playing, ignoring play request");
      return;
    }

    console.log("‚ñ∂Ô∏è Play function called");
    console.log("- use_backend_audio:", use_backend_audio);
    console.log("- audio_data present:", !!audio_data);
    console.log("- elem_id:", elem_id);

    // Ïû¨ÏÉù Ïù¥Î≤§Ìä∏ Î∞úÏÉù
    dispatch('play', {
      currentPosition: currentFlicks,
      notes,
      tempo,
      use_backend_audio
    });

    if (use_backend_audio && audio_data) {
      console.log("üéµ Using backend audio for playback");
      // Î∞±ÏóîÎìú Ïò§ÎîîÏò§ Ïû¨ÏÉù
      handleBackendAudioInit().then(() => {
        handleBackendAudioPlay();
      }).catch((error) => {
        console.error("‚ùå Backend audio initialization failed:", error);
        fallbackToFrontendAudio();
      });
      return;
    }

    console.log("üéµ Using frontend audio engine");
    if (!audioEngine.getRenderedBuffer()) {
      console.log("üîÑ No rendered buffer, rendering first...");
      // Render audio first if not already rendered
      renderAudio().then(() => {
        startPlayback();
      });
    } else {
      console.log("‚úÖ Rendered buffer ready, starting playback");
      startPlayback();
    }
  }

  function fallbackToFrontendAudio() {
    console.log("üîÑ Falling back to frontend audio engine");
    use_backend_audio = false;
    if (!audioEngine.getRenderedBuffer()) {
      renderAudio().then(() => {
        startPlayback();
      });
    } else {
      startPlayback();
    }
  }

  function startPlayback() {
    if (use_backend_audio) {
      console.log("‚ö†Ô∏è startPlayback called but use_backend_audio is true - should not happen");
      return; // Î∞±ÏóîÎìú Ïò§ÎîîÏò§ ÏÇ¨Ïö© Ïãú Í±¥ÎÑàÎõ∞Í∏∞
    }

    console.log("‚ñ∂Ô∏è Starting frontend audio playback");
    audioEngine.play();
    isPlaying = true;
  }

  function pause() {
    console.log("‚è∏Ô∏è Pause function called");
    console.log("- use_backend_audio:", use_backend_audio);

    // ÏùºÏãúÏ†ïÏßÄ Ïù¥Î≤§Ìä∏ Î∞úÏÉù
    dispatch('pause', {
      currentPosition: currentFlicks,
      use_backend_audio
    });

    if (use_backend_audio) {
      handleBackendAudioPause();
      return;
    }

    console.log("‚è∏Ô∏è Pausing frontend audio");
    audioEngine.pause();
    isPlaying = false;
  }

  function stop() {
    console.log("‚èπÔ∏è Stop function called");
    console.log("- use_backend_audio:", use_backend_audio);

    // Ï†ïÏßÄ Ïù¥Î≤§Ìä∏ Î∞úÏÉù
    dispatch('stop', {
      currentPosition: currentFlicks,
      use_backend_audio
    });

    if (use_backend_audio) {
      handleBackendAudioStop();
      return;
    }

    console.log("‚èπÔ∏è Stopping frontend audio");
    audioEngine.stop();
    isPlaying = false;
    currentFlicks = 0;
    // Also reset the audio engine's internal position
    audioEngine.seekToFlicks(0);
  }

  // Ïò§ÎîîÏò§ Îã§Ïö¥Î°úÎìú Ìï®Ïàò
  async function downloadAudio() {
    console.log("üíæ Download audio function called");
    console.log("- use_backend_audio:", use_backend_audio);
    console.log("- audio_data present:", !!audio_data);

    if (use_backend_audio && audio_data) {
      // Î∞±ÏóîÎìú Ïò§ÎîîÏò§ Îã§Ïö¥Î°úÎìú
      isRendering = true;
      try {
        await handleBackendAudioDownload();
      } finally {
        isRendering = false;
      }
    } else {
      // ÌîÑÎ°†Ìä∏ÏóîÎìú Ïò§ÎîîÏò§ Îã§Ïö¥Î°úÎìú
      await downloadFrontendAudio();
    }
  }

  // ÌîÑÎ°†Ìä∏ÏóîÎìú Ïò§ÎîîÏò§ Îã§Ïö¥Î°úÎìú (Î†åÎçîÎßÅ ÌõÑ WAVÎ°ú Î≥ÄÌôò)
  async function downloadFrontendAudio() {
    console.log("üíæ Downloading frontend audio...");

    try {
      // Ïò§ÎîîÏò§Í∞Ä Î†åÎçîÎßÅÎêòÏßÄ ÏïäÏïòÎã§Î©¥ Î®ºÏ†Ä Î†åÎçîÎßÅ
      if (!audioEngine.getRenderedBuffer()) {
        console.log("üîÑ No rendered buffer, rendering audio first...");
        isRendering = true;
        await renderAudio();
        isRendering = false;
      }

      // Î†åÎçîÎßÅÎêú Ïò§ÎîîÏò§Í∞Ä ÏûàÎäîÏßÄ ÌôïÏù∏
      if (!audioEngine.getRenderedBuffer()) {
        console.error("‚ùå Failed to render audio for download");
        return;
      }

      // ÌååÏùºÎ™Ö ÏÉùÏÑ± (ÌòÑÏû¨ ÏãúÍ∞Ñ Ìè¨Ìï®)
      const now = new Date();
      const timestamp = now.toISOString().slice(0, 19).replace(/[T:]/g, '_');
      const filename = `piano_roll_${timestamp}.wav`;

      // Îã§Ïö¥Î°úÎìú Ïã§Ìñâ
      audioEngine.downloadAudio(filename);

      console.log("‚úÖ Frontend audio download initiated:", filename);
    } catch (error) {
      console.error("‚ùå Error downloading frontend audio:", error);
    } finally {
      isRendering = false;
    }
  }

  function togglePlayback() {
    if (isPlaying) {
      pause();
    } else {
      play();
    }
  }

  // Handle position updates from audio engine
  function updatePlayheadPosition(flicks: number) {
    currentFlicks = flicks;

    // Check if playhead is out of view and scroll to keep it visible
    const positionInBeats = flicksToBeats(flicks, tempo);
    const positionInPixels = positionInBeats * pixelsPerBeat;

    // Auto-scroll if playhead is near the edge of the view
    const bufferPixels = 100; // Buffer to start scrolling before edge
    if (positionInPixels > horizontalScroll + width - bufferPixels) {
      horizontalScroll = Math.max(0, positionInPixels - width / 2);
    } else if (positionInPixels < horizontalScroll + bufferPixels) {
      horizontalScroll = Math.max(0, positionInPixels - bufferPixels);
    }
  }

  // Handle note changes to re-render audio
  function handleNoteChange(event: CustomEvent) {
    notes = event.detail.notes;
    // Re-render audio when notes change
    renderAudio();
    // ÎÖ∏Ìä∏ Î≥ÄÍ≤Ω Ïù¥Î≤§Ìä∏ Î∞úÏÉù
    dispatchNoteChange();
  }

  // Handle tempo changes
  function handleTempoChange(event: CustomEvent) {
    tempo = event.detail;
    // Re-render audio when tempo changes
    renderAudio();
    // Ï†ÑÏ≤¥ Îç∞Ïù¥ÌÑ∞ Î≥ÄÍ≤Ω Ïù¥Î≤§Ìä∏ Î∞úÏÉù
    dispatchDataChange();
  }

  // Handle position change from timeline click
  function handlePositionChange(event: CustomEvent) {
    const { flicks } = event.detail;
    currentFlicks = flicks;

    // Seek audio engine to new position
    audioEngine.seekToFlicks(flicks);
  }

  // Í∞ÄÏÇ¨ ÏûÖÎ†• Ïù¥Î≤§Ìä∏ Î∞úÏÉù (GridComponentÏóêÏÑú Ï†ÑÎã¨Î∞õÏùÄ Í≤ÉÏùÑ ÏÉÅÏúÑÎ°ú Ï†ÑÎã¨)
  function handleLyricInput(event: CustomEvent) {
    dispatch('lyricInput', event.detail);
  }

  onMount(() => {
    // Set up playhead position update callback
    audioEngine.setPlayheadUpdateCallback(updatePlayheadPosition);

    // Initial audio render - Î∞±ÏóîÎìú Ïò§ÎîîÏò§Î•º ÏÇ¨Ïö©ÌïòÏßÄ ÏïäÎäî Í≤ΩÏö∞ Ìï≠ÏÉÅ Î†åÎçîÎßÅ
    if (!use_backend_audio) {
      console.log("üéµ Initial frontend audio rendering on mount");
      renderAudio();
    }
  });

  onDestroy(() => {
    // Clean up backend audio
    // backendAudioEngine.dispose(); // Î∞±ÏóîÎìú Ïò§ÎîîÏò§ ÏóîÏßÑ Ï†ïÎ¶¨

    // Clean up component-specific audio engine resources
    if (elem_id) {
      AudioEngineManager.disposeInstance(elem_id);
    } else {
      audioEngine.dispose();
    }
  });

  // Reactive statement to decode backend audio when audio_data changes
  $: if (audio_data && use_backend_audio) {
    console.log("üîÑ Audio data or backend flag changed, initializing...");
    console.log("- audio_data present:", !!audio_data);
    console.log("- use_backend_audio:", use_backend_audio);

    handleBackendAudioInit().catch((error) => {
      console.error("‚ùå Failed to initialize backend audio:", error);
    });
  }

  // Reactive statement to start frontend rendering when switching from backend to frontend
  $: if (!use_backend_audio && audioEngine) {
    console.log("üîÑ Switched to frontend audio - starting automatic rendering");
    renderAudio();
  }
</script>

<div
  class="piano-roll-container"
  bind:this={containerElement}
  style="width: {width}px; height: {height}px;"
>
  <Toolbar
    {tempo}
    {timeSignature}
    {editMode}
    {snapSetting}
    {isPlaying}
    {isRendering}
    on:tempoChange={handleTempoChange}
    on:timeSignatureChange={handleTimeSignatureChange}
    on:editModeChange={handleEditModeChange}
    on:snapChange={handleSnapChange}
    on:zoomChange={handleZoomChange}
    on:play={play}
    on:pause={pause}
    on:stop={stop}
    on:togglePlay={togglePlayback}
    on:downloadAudio={downloadAudio}
  />

  <div class="piano-roll-main" style="height: {height - 40}px;">
    <!-- Timeline positioned at the top -->
    <div class="timeline-container" style="margin-left: {keyboardWidth}px;">
      <TimeLineComponent
        width={width - keyboardWidth}
        {timelineHeight}
        {timeSignature}
        {snapSetting}
        {horizontalScroll}
        {pixelsPerBeat}
        {tempo}
        on:zoomChange={handleZoomChange}
        on:positionChange={handlePositionChange}
      />
    </div>

    <!-- Main content area with keyboard and grid aligned -->
    <div class="content-container">
      <KeyboardComponent
        {keyboardWidth}
        height={height - 40 - timelineHeight}
        {verticalScroll}
      />

      <div class="grid-container" style="position: relative;">
        <!-- Waveform is now handled by the layer system in GridComponent -->
        <!-- <WaveformComponent> has been integrated into WaveformLayer -->

        <!-- Grid component containing notes and grid lines -->
        <GridComponent
          width={width - keyboardWidth}
          height={height - 40 - timelineHeight}
          {notes}
          {tempo}
          {timeSignature}
          {editMode}
          {snapSetting}
          {horizontalScroll}
          {verticalScroll}
          {pixelsPerBeat}
          {currentFlicks}
          {isPlaying}
          {sampleRate}
          {ppqn}
          {elem_id}
          {audio_data}
          {curve_data}
          {line_data}
          {use_backend_audio}
          on:scroll={handleGridScroll}
          on:noteChange={handleNoteChange}
          on:lyricInput={handleLyricInput}
        />

        <!-- Playhead position indicator -->
        <PlayheadComponent
          width={width - keyboardWidth}
          height={height - 40 - timelineHeight}
          {horizontalScroll}
          {pixelsPerBeat}
          {tempo}
          {currentFlicks}
          {isPlaying}
        />
      </div>
    </div>
  </div>
</div>

<!-- Debug component for Flicks timing information -->
<DebugComponent
  {currentFlicks}
  {tempo}
  {notes}
  {isPlaying}
  {isRendering}
/>

<style>
  .piano-roll-container {
    display: flex;
    flex-direction: column;
    overflow: hidden;
    background-color: #2c2c2c;
    border-radius: 5px;
    box-shadow: 0 4px 8px rgba(0, 0, 0, 0.2);
    font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, Helvetica, Arial, sans-serif;
  }

  .piano-roll-main {
    display: flex;
    flex-direction: column;
    flex: 1;
  }

  .timeline-container {
    display: flex;
    height: var(--timeline-height, 40px);
  }

  .content-container {
    display: flex;
    flex-direction: row;
    flex: 1;
  }
</style>
